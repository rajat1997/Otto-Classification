{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98ebe54d",
   "metadata": {},
   "source": [
    "# Rajat Sharma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07294d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "163735ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('otto.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa69d135",
   "metadata": {},
   "source": [
    "### (Load the original data, print out the exact number of instances and number of classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfe229fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>feat_3</th>\n",
       "      <th>feat_4</th>\n",
       "      <th>feat_5</th>\n",
       "      <th>feat_6</th>\n",
       "      <th>feat_7</th>\n",
       "      <th>feat_8</th>\n",
       "      <th>feat_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_85</th>\n",
       "      <th>feat_86</th>\n",
       "      <th>feat_87</th>\n",
       "      <th>feat_88</th>\n",
       "      <th>feat_89</th>\n",
       "      <th>feat_90</th>\n",
       "      <th>feat_91</th>\n",
       "      <th>feat_92</th>\n",
       "      <th>feat_93</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  feat_1  feat_2  feat_3  feat_4  feat_5  feat_6  feat_7  feat_8  feat_9  \\\n",
       "0   1       1       0       0       0       0       0       0       0       0   \n",
       "1   2       0       0       0       0       0       0       0       1       0   \n",
       "2   3       0       0       0       0       0       0       0       1       0   \n",
       "3   4       1       0       0       1       6       1       5       0       0   \n",
       "4   5       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   ...  feat_85  feat_86  feat_87  feat_88  feat_89  feat_90  feat_91  \\\n",
       "0  ...        1        0        0        0        0        0        0   \n",
       "1  ...        0        0        0        0        0        0        0   \n",
       "2  ...        0        0        0        0        0        0        0   \n",
       "3  ...        0        1        2        0        0        0        0   \n",
       "4  ...        1        0        0        0        0        1        0   \n",
       "\n",
       "   feat_92  feat_93   target  \n",
       "0        0        0  Class_1  \n",
       "1        0        0  Class_1  \n",
       "2        0        0  Class_1  \n",
       "3        0        0  Class_1  \n",
       "4        0        0  Class_1  \n",
       "\n",
       "[5 rows x 95 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfe5da66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61878, 95)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13a7a7ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 61878 entries, 0 to 61877\n",
      "Data columns (total 95 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   id       61878 non-null  int64 \n",
      " 1   feat_1   61878 non-null  int64 \n",
      " 2   feat_2   61878 non-null  int64 \n",
      " 3   feat_3   61878 non-null  int64 \n",
      " 4   feat_4   61878 non-null  int64 \n",
      " 5   feat_5   61878 non-null  int64 \n",
      " 6   feat_6   61878 non-null  int64 \n",
      " 7   feat_7   61878 non-null  int64 \n",
      " 8   feat_8   61878 non-null  int64 \n",
      " 9   feat_9   61878 non-null  int64 \n",
      " 10  feat_10  61878 non-null  int64 \n",
      " 11  feat_11  61878 non-null  int64 \n",
      " 12  feat_12  61878 non-null  int64 \n",
      " 13  feat_13  61878 non-null  int64 \n",
      " 14  feat_14  61878 non-null  int64 \n",
      " 15  feat_15  61878 non-null  int64 \n",
      " 16  feat_16  61878 non-null  int64 \n",
      " 17  feat_17  61878 non-null  int64 \n",
      " 18  feat_18  61878 non-null  int64 \n",
      " 19  feat_19  61878 non-null  int64 \n",
      " 20  feat_20  61878 non-null  int64 \n",
      " 21  feat_21  61878 non-null  int64 \n",
      " 22  feat_22  61878 non-null  int64 \n",
      " 23  feat_23  61878 non-null  int64 \n",
      " 24  feat_24  61878 non-null  int64 \n",
      " 25  feat_25  61878 non-null  int64 \n",
      " 26  feat_26  61878 non-null  int64 \n",
      " 27  feat_27  61878 non-null  int64 \n",
      " 28  feat_28  61878 non-null  int64 \n",
      " 29  feat_29  61878 non-null  int64 \n",
      " 30  feat_30  61878 non-null  int64 \n",
      " 31  feat_31  61878 non-null  int64 \n",
      " 32  feat_32  61878 non-null  int64 \n",
      " 33  feat_33  61878 non-null  int64 \n",
      " 34  feat_34  61878 non-null  int64 \n",
      " 35  feat_35  61878 non-null  int64 \n",
      " 36  feat_36  61878 non-null  int64 \n",
      " 37  feat_37  61878 non-null  int64 \n",
      " 38  feat_38  61878 non-null  int64 \n",
      " 39  feat_39  61878 non-null  int64 \n",
      " 40  feat_40  61878 non-null  int64 \n",
      " 41  feat_41  61878 non-null  int64 \n",
      " 42  feat_42  61878 non-null  int64 \n",
      " 43  feat_43  61878 non-null  int64 \n",
      " 44  feat_44  61878 non-null  int64 \n",
      " 45  feat_45  61878 non-null  int64 \n",
      " 46  feat_46  61878 non-null  int64 \n",
      " 47  feat_47  61878 non-null  int64 \n",
      " 48  feat_48  61878 non-null  int64 \n",
      " 49  feat_49  61878 non-null  int64 \n",
      " 50  feat_50  61878 non-null  int64 \n",
      " 51  feat_51  61878 non-null  int64 \n",
      " 52  feat_52  61878 non-null  int64 \n",
      " 53  feat_53  61878 non-null  int64 \n",
      " 54  feat_54  61878 non-null  int64 \n",
      " 55  feat_55  61878 non-null  int64 \n",
      " 56  feat_56  61878 non-null  int64 \n",
      " 57  feat_57  61878 non-null  int64 \n",
      " 58  feat_58  61878 non-null  int64 \n",
      " 59  feat_59  61878 non-null  int64 \n",
      " 60  feat_60  61878 non-null  int64 \n",
      " 61  feat_61  61878 non-null  int64 \n",
      " 62  feat_62  61878 non-null  int64 \n",
      " 63  feat_63  61878 non-null  int64 \n",
      " 64  feat_64  61878 non-null  int64 \n",
      " 65  feat_65  61878 non-null  int64 \n",
      " 66  feat_66  61878 non-null  int64 \n",
      " 67  feat_67  61878 non-null  int64 \n",
      " 68  feat_68  61878 non-null  int64 \n",
      " 69  feat_69  61878 non-null  int64 \n",
      " 70  feat_70  61878 non-null  int64 \n",
      " 71  feat_71  61878 non-null  int64 \n",
      " 72  feat_72  61878 non-null  int64 \n",
      " 73  feat_73  61878 non-null  int64 \n",
      " 74  feat_74  61878 non-null  int64 \n",
      " 75  feat_75  61878 non-null  int64 \n",
      " 76  feat_76  61878 non-null  int64 \n",
      " 77  feat_77  61878 non-null  int64 \n",
      " 78  feat_78  61878 non-null  int64 \n",
      " 79  feat_79  61878 non-null  int64 \n",
      " 80  feat_80  61878 non-null  int64 \n",
      " 81  feat_81  61878 non-null  int64 \n",
      " 82  feat_82  61878 non-null  int64 \n",
      " 83  feat_83  61878 non-null  int64 \n",
      " 84  feat_84  61878 non-null  int64 \n",
      " 85  feat_85  61878 non-null  int64 \n",
      " 86  feat_86  61878 non-null  int64 \n",
      " 87  feat_87  61878 non-null  int64 \n",
      " 88  feat_88  61878 non-null  int64 \n",
      " 89  feat_89  61878 non-null  int64 \n",
      " 90  feat_90  61878 non-null  int64 \n",
      " 91  feat_91  61878 non-null  int64 \n",
      " 92  feat_92  61878 non-null  int64 \n",
      " 93  feat_93  61878 non-null  int64 \n",
      " 94  target   61878 non-null  object\n",
      "dtypes: int64(94), object(1)\n",
      "memory usage: 44.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a167130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>feat_3</th>\n",
       "      <th>feat_4</th>\n",
       "      <th>feat_5</th>\n",
       "      <th>feat_6</th>\n",
       "      <th>feat_7</th>\n",
       "      <th>feat_8</th>\n",
       "      <th>feat_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_85</th>\n",
       "      <th>feat_86</th>\n",
       "      <th>feat_87</th>\n",
       "      <th>feat_88</th>\n",
       "      <th>feat_89</th>\n",
       "      <th>feat_90</th>\n",
       "      <th>feat_91</th>\n",
       "      <th>feat_92</th>\n",
       "      <th>feat_93</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.00000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Class_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>30939.500000</td>\n",
       "      <td>0.38668</td>\n",
       "      <td>0.263066</td>\n",
       "      <td>0.901467</td>\n",
       "      <td>0.779081</td>\n",
       "      <td>0.071043</td>\n",
       "      <td>0.025696</td>\n",
       "      <td>0.193704</td>\n",
       "      <td>0.662433</td>\n",
       "      <td>1.011296</td>\n",
       "      <td>...</td>\n",
       "      <td>0.532306</td>\n",
       "      <td>1.128576</td>\n",
       "      <td>0.393549</td>\n",
       "      <td>0.874915</td>\n",
       "      <td>0.457772</td>\n",
       "      <td>0.812421</td>\n",
       "      <td>0.264941</td>\n",
       "      <td>0.380119</td>\n",
       "      <td>0.126135</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>17862.784315</td>\n",
       "      <td>1.52533</td>\n",
       "      <td>1.252073</td>\n",
       "      <td>2.934818</td>\n",
       "      <td>2.788005</td>\n",
       "      <td>0.438902</td>\n",
       "      <td>0.215333</td>\n",
       "      <td>1.030102</td>\n",
       "      <td>2.255770</td>\n",
       "      <td>3.474822</td>\n",
       "      <td>...</td>\n",
       "      <td>1.900438</td>\n",
       "      <td>2.681554</td>\n",
       "      <td>1.575455</td>\n",
       "      <td>2.115466</td>\n",
       "      <td>1.527385</td>\n",
       "      <td>4.597804</td>\n",
       "      <td>2.045646</td>\n",
       "      <td>0.982385</td>\n",
       "      <td>1.201720</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>15470.250000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>30939.500000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>46408.750000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61.00000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id       feat_1        feat_2        feat_3        feat_4  \\\n",
       "count   61878.000000  61878.00000  61878.000000  61878.000000  61878.000000   \n",
       "unique           NaN          NaN           NaN           NaN           NaN   \n",
       "top              NaN          NaN           NaN           NaN           NaN   \n",
       "freq             NaN          NaN           NaN           NaN           NaN   \n",
       "mean    30939.500000      0.38668      0.263066      0.901467      0.779081   \n",
       "std     17862.784315      1.52533      1.252073      2.934818      2.788005   \n",
       "min         1.000000      0.00000      0.000000      0.000000      0.000000   \n",
       "25%     15470.250000      0.00000      0.000000      0.000000      0.000000   \n",
       "50%     30939.500000      0.00000      0.000000      0.000000      0.000000   \n",
       "75%     46408.750000      0.00000      0.000000      0.000000      0.000000   \n",
       "max     61878.000000     61.00000     51.000000     64.000000     70.000000   \n",
       "\n",
       "              feat_5        feat_6        feat_7        feat_8        feat_9  \\\n",
       "count   61878.000000  61878.000000  61878.000000  61878.000000  61878.000000   \n",
       "unique           NaN           NaN           NaN           NaN           NaN   \n",
       "top              NaN           NaN           NaN           NaN           NaN   \n",
       "freq             NaN           NaN           NaN           NaN           NaN   \n",
       "mean        0.071043      0.025696      0.193704      0.662433      1.011296   \n",
       "std         0.438902      0.215333      1.030102      2.255770      3.474822   \n",
       "min         0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%         0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%         0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%         0.000000      0.000000      0.000000      1.000000      0.000000   \n",
       "max        19.000000     10.000000     38.000000     76.000000     43.000000   \n",
       "\n",
       "        ...       feat_85       feat_86       feat_87       feat_88  \\\n",
       "count   ...  61878.000000  61878.000000  61878.000000  61878.000000   \n",
       "unique  ...           NaN           NaN           NaN           NaN   \n",
       "top     ...           NaN           NaN           NaN           NaN   \n",
       "freq    ...           NaN           NaN           NaN           NaN   \n",
       "mean    ...      0.532306      1.128576      0.393549      0.874915   \n",
       "std     ...      1.900438      2.681554      1.575455      2.115466   \n",
       "min     ...      0.000000      0.000000      0.000000      0.000000   \n",
       "25%     ...      0.000000      0.000000      0.000000      0.000000   \n",
       "50%     ...      0.000000      0.000000      0.000000      0.000000   \n",
       "75%     ...      0.000000      1.000000      0.000000      1.000000   \n",
       "max     ...     55.000000     65.000000     67.000000     30.000000   \n",
       "\n",
       "             feat_89       feat_90       feat_91       feat_92       feat_93  \\\n",
       "count   61878.000000  61878.000000  61878.000000  61878.000000  61878.000000   \n",
       "unique           NaN           NaN           NaN           NaN           NaN   \n",
       "top              NaN           NaN           NaN           NaN           NaN   \n",
       "freq             NaN           NaN           NaN           NaN           NaN   \n",
       "mean        0.457772      0.812421      0.264941      0.380119      0.126135   \n",
       "std         1.527385      4.597804      2.045646      0.982385      1.201720   \n",
       "min         0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%         0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%         0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%         0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        61.000000    130.000000     52.000000     19.000000     87.000000   \n",
       "\n",
       "         target  \n",
       "count     61878  \n",
       "unique        9  \n",
       "top     Class_2  \n",
       "freq      16122  \n",
       "mean        NaN  \n",
       "std         NaN  \n",
       "min         NaN  \n",
       "25%         NaN  \n",
       "50%         NaN  \n",
       "75%         NaN  \n",
       "max         NaN  \n",
       "\n",
       "[11 rows x 95 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5ae760",
   "metadata": {},
   "source": [
    "### (handle missing values in the dataset, remove non-numerical class labels if there exists any, and filtering out rows with all zero values.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea360e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts null for each column:\n",
      "id         0\n",
      "feat_1     0\n",
      "feat_2     0\n",
      "feat_3     0\n",
      "feat_4     0\n",
      "          ..\n",
      "feat_90    0\n",
      "feat_91    0\n",
      "feat_92    0\n",
      "feat_93    0\n",
      "target     0\n",
      "Length: 95, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Counts null for each column:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2121ee2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cec869da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>feat_3</th>\n",
       "      <th>feat_4</th>\n",
       "      <th>feat_5</th>\n",
       "      <th>feat_6</th>\n",
       "      <th>feat_7</th>\n",
       "      <th>feat_8</th>\n",
       "      <th>feat_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_85</th>\n",
       "      <th>feat_86</th>\n",
       "      <th>feat_87</th>\n",
       "      <th>feat_88</th>\n",
       "      <th>feat_89</th>\n",
       "      <th>feat_90</th>\n",
       "      <th>feat_91</th>\n",
       "      <th>feat_92</th>\n",
       "      <th>feat_93</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  feat_1  feat_2  feat_3  feat_4  feat_5  feat_6  feat_7  feat_8  feat_9  \\\n",
       "0   1       1       0       0       0       0       0       0       0       0   \n",
       "1   2       0       0       0       0       0       0       0       1       0   \n",
       "2   3       0       0       0       0       0       0       0       1       0   \n",
       "3   4       1       0       0       1       6       1       5       0       0   \n",
       "4   5       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   ...  feat_85  feat_86  feat_87  feat_88  feat_89  feat_90  feat_91  \\\n",
       "0  ...        1        0        0        0        0        0        0   \n",
       "1  ...        0        0        0        0        0        0        0   \n",
       "2  ...        0        0        0        0        0        0        0   \n",
       "3  ...        0        1        2        0        0        0        0   \n",
       "4  ...        1        0        0        0        0        1        0   \n",
       "\n",
       "   feat_92  feat_93   target  \n",
       "0        0        0  Class_1  \n",
       "1        0        0  Class_1  \n",
       "2        0        0  Class_1  \n",
       "3        0        0  Class_1  \n",
       "4        0        0  Class_1  \n",
       "\n",
       "[5 rows x 95 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be6dbb87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>feat_3</th>\n",
       "      <th>feat_4</th>\n",
       "      <th>feat_5</th>\n",
       "      <th>feat_6</th>\n",
       "      <th>feat_7</th>\n",
       "      <th>feat_8</th>\n",
       "      <th>feat_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_84</th>\n",
       "      <th>feat_85</th>\n",
       "      <th>feat_86</th>\n",
       "      <th>feat_87</th>\n",
       "      <th>feat_88</th>\n",
       "      <th>feat_89</th>\n",
       "      <th>feat_90</th>\n",
       "      <th>feat_91</th>\n",
       "      <th>feat_92</th>\n",
       "      <th>feat_93</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.00000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61878.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>30939.500000</td>\n",
       "      <td>0.38668</td>\n",
       "      <td>0.263066</td>\n",
       "      <td>0.901467</td>\n",
       "      <td>0.779081</td>\n",
       "      <td>0.071043</td>\n",
       "      <td>0.025696</td>\n",
       "      <td>0.193704</td>\n",
       "      <td>0.662433</td>\n",
       "      <td>1.011296</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070752</td>\n",
       "      <td>0.532306</td>\n",
       "      <td>1.128576</td>\n",
       "      <td>0.393549</td>\n",
       "      <td>0.874915</td>\n",
       "      <td>0.457772</td>\n",
       "      <td>0.812421</td>\n",
       "      <td>0.264941</td>\n",
       "      <td>0.380119</td>\n",
       "      <td>0.126135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>17862.784315</td>\n",
       "      <td>1.52533</td>\n",
       "      <td>1.252073</td>\n",
       "      <td>2.934818</td>\n",
       "      <td>2.788005</td>\n",
       "      <td>0.438902</td>\n",
       "      <td>0.215333</td>\n",
       "      <td>1.030102</td>\n",
       "      <td>2.255770</td>\n",
       "      <td>3.474822</td>\n",
       "      <td>...</td>\n",
       "      <td>1.151460</td>\n",
       "      <td>1.900438</td>\n",
       "      <td>2.681554</td>\n",
       "      <td>1.575455</td>\n",
       "      <td>2.115466</td>\n",
       "      <td>1.527385</td>\n",
       "      <td>4.597804</td>\n",
       "      <td>2.045646</td>\n",
       "      <td>0.982385</td>\n",
       "      <td>1.201720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>15470.250000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>30939.500000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>46408.750000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>61878.000000</td>\n",
       "      <td>61.00000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>87.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 94 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id       feat_1        feat_2        feat_3        feat_4  \\\n",
       "count  61878.000000  61878.00000  61878.000000  61878.000000  61878.000000   \n",
       "mean   30939.500000      0.38668      0.263066      0.901467      0.779081   \n",
       "std    17862.784315      1.52533      1.252073      2.934818      2.788005   \n",
       "min        1.000000      0.00000      0.000000      0.000000      0.000000   \n",
       "25%    15470.250000      0.00000      0.000000      0.000000      0.000000   \n",
       "50%    30939.500000      0.00000      0.000000      0.000000      0.000000   \n",
       "75%    46408.750000      0.00000      0.000000      0.000000      0.000000   \n",
       "max    61878.000000     61.00000     51.000000     64.000000     70.000000   \n",
       "\n",
       "             feat_5        feat_6        feat_7        feat_8        feat_9  \\\n",
       "count  61878.000000  61878.000000  61878.000000  61878.000000  61878.000000   \n",
       "mean       0.071043      0.025696      0.193704      0.662433      1.011296   \n",
       "std        0.438902      0.215333      1.030102      2.255770      3.474822   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      1.000000      0.000000   \n",
       "max       19.000000     10.000000     38.000000     76.000000     43.000000   \n",
       "\n",
       "       ...       feat_84       feat_85       feat_86       feat_87  \\\n",
       "count  ...  61878.000000  61878.000000  61878.000000  61878.000000   \n",
       "mean   ...      0.070752      0.532306      1.128576      0.393549   \n",
       "std    ...      1.151460      1.900438      2.681554      1.575455   \n",
       "min    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "25%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "50%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "75%    ...      0.000000      0.000000      1.000000      0.000000   \n",
       "max    ...     76.000000     55.000000     65.000000     67.000000   \n",
       "\n",
       "            feat_88       feat_89       feat_90       feat_91       feat_92  \\\n",
       "count  61878.000000  61878.000000  61878.000000  61878.000000  61878.000000   \n",
       "mean       0.874915      0.457772      0.812421      0.264941      0.380119   \n",
       "std        2.115466      1.527385      4.597804      2.045646      0.982385   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        1.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max       30.000000     61.000000    130.000000     52.000000     19.000000   \n",
       "\n",
       "            feat_93  \n",
       "count  61878.000000  \n",
       "mean       0.126135  \n",
       "std        1.201720  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.000000  \n",
       "max       87.000000  \n",
       "\n",
       "[8 rows x 94 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c993906",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "61873    8\n",
       "61874    8\n",
       "61875    8\n",
       "61876    8\n",
       "61877    8\n",
       "Name: target, Length: 61878, dtype: int8"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"target\"] = df[\"target\"].astype('category')\n",
    "df[\"target\"] = df[\"target\"].cat.codes\n",
    "df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80236c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['target'],axis=1).values   \n",
    "y = df['target'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b75c8e",
   "metadata": {},
   "source": [
    "### (Split the original data into two parts: 80% for training and 20% for testing.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df9c66ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44ea71f",
   "metadata": {},
   "source": [
    "## Algorithm Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee3d79a",
   "metadata": {},
   "source": [
    "### (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b075f6d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       400\n",
      "           1       1.00      1.00      1.00      3262\n",
      "           2       1.00      1.00      1.00      1562\n",
      "           3       1.00      1.00      1.00       558\n",
      "           4       1.00      1.00      1.00       559\n",
      "           5       1.00      1.00      1.00      2843\n",
      "           6       1.00      1.00      1.00       534\n",
      "           7       1.00      1.00      1.00      1653\n",
      "           8       1.00      1.00      1.00      1005\n",
      "\n",
      "    accuracy                           1.00     12376\n",
      "   macro avg       1.00      1.00      1.00     12376\n",
      "weighted avg       1.00      1.00      1.00     12376\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "knn_predictions = knn.predict(X_test)\n",
    "print(classification_report(y_test , knn_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52daa3bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, knn_predictions)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555ddac0",
   "metadata": {},
   "source": [
    "### (Logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ed931ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8 2 2 ... 2 4 5]\n",
      "77.1978021978022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lor = LogisticRegression() \n",
    "\n",
    "lor.fit(X_train, y_train) \n",
    "\n",
    "import re\n",
    "lor_predictions  = lor.predict(X_test)\n",
    "print(lor_predictions)\n",
    "print(lor.score(X_test, y_test)*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4606695c",
   "metadata": {},
   "source": [
    "### (Linear Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4c588cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression() \n",
    "#training\n",
    "lr.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16d8fe15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.98614484 1.84115703 1.65916434 ... 2.66024387 3.68741063 4.36772916]\n",
      "96.14496783109361\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "lr_predictions  = lr.predict(X_test)\n",
    "print(lr_predictions)\n",
    "print(lr.score(X_test, y_test)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacd5b7e",
   "metadata": {},
   "source": [
    "### (Decision Tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3b8a14b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       400\n",
      "           1       1.00      1.00      1.00      3262\n",
      "           2       1.00      1.00      1.00      1562\n",
      "           3       1.00      1.00      1.00       558\n",
      "           4       1.00      1.00      1.00       559\n",
      "           5       1.00      1.00      1.00      2843\n",
      "           6       1.00      1.00      1.00       534\n",
      "           7       1.00      1.00      1.00      1653\n",
      "           8       1.00      1.00      1.00      1005\n",
      "\n",
      "    accuracy                           1.00     12376\n",
      "   macro avg       1.00      1.00      1.00     12376\n",
      "weighted avg       1.00      1.00      1.00     12376\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "dt = tree.DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "import re\n",
    "dt_predictions  = dt.predict(X_test)\n",
    "print(classification_report(y_test , dt_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a937797d",
   "metadata": {},
   "source": [
    "### (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "903b5c38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced', max_depth=5, n_estimators=1000,\n",
       "                       random_state=3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators = 1000,max_depth = 5, class_weight = 'balanced',random_state= 3)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "11e65848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96       400\n",
      "           1       1.00      0.97      0.98      3262\n",
      "           2       0.98      0.91      0.94      1562\n",
      "           3       0.65      0.91      0.76       558\n",
      "           4       0.71      0.97      0.82       559\n",
      "           5       0.98      0.85      0.91      2843\n",
      "           6       0.65      0.70      0.67       534\n",
      "           7       0.93      0.92      0.92      1653\n",
      "           8       0.89      1.00      0.94      1005\n",
      "\n",
      "    accuracy                           0.92     12376\n",
      "   macro avg       0.86      0.91      0.88     12376\n",
      "weighted avg       0.93      0.92      0.92     12376\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "rf_predictions  = rf.predict(X_test)\n",
    "print(classification_report(y_test , rf_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "08c9c91f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91.54815772462831"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, rf_predictions)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2be64b4",
   "metadata": {},
   "source": [
    "### (Neural Network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0f333f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98       400\n",
      "           1       0.97      1.00      0.98      3262\n",
      "           2       0.95      0.94      0.95      1562\n",
      "           3       0.98      0.85      0.91       558\n",
      "           4       0.96      0.99      0.98       559\n",
      "           5       0.98      0.99      0.98      2843\n",
      "           6       0.95      0.88      0.91       534\n",
      "           7       0.98      0.96      0.97      1653\n",
      "           8       0.95      0.99      0.97      1005\n",
      "\n",
      "    accuracy                           0.97     12376\n",
      "   macro avg       0.97      0.95      0.96     12376\n",
      "weighted avg       0.97      0.97      0.97     12376\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(8,8,8), activation='relu', solver='adam', max_iter=500)\n",
    "mlp.fit(X_train,y_train)\n",
    "mlp_predictions = mlp.predict(X_test)\n",
    "print(classification_report(y_test , mlp_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ad807b02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97.03458306399483"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, mlp_predictions)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a613a13f",
   "metadata": {},
   "source": [
    "### (Naive Bayes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b275b9cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.88      0.91       400\n",
      "           1       0.86      0.63      0.73      3262\n",
      "           2       0.46      0.29      0.35      1562\n",
      "           3       0.23      0.78      0.35       558\n",
      "           4       0.70      0.97      0.81       559\n",
      "           5       0.93      0.80      0.86      2843\n",
      "           6       0.54      0.63      0.58       534\n",
      "           7       0.91      0.68      0.78      1653\n",
      "           8       0.57      0.92      0.71      1005\n",
      "\n",
      "    accuracy                           0.69     12376\n",
      "   macro avg       0.68      0.73      0.68     12376\n",
      "weighted avg       0.76      0.69      0.70     12376\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)\n",
    "nb_predictions  = clf.predict(X_test)\n",
    "print(classification_report(y_test , nb_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "89a5947f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68.80252100840336"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, nb_predictions)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf74c0cf",
   "metadata": {},
   "source": [
    "### (AdaBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6ea33ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       400\n",
      "           1       1.00      1.00      1.00      3262\n",
      "           2       0.00      0.00      0.00      1562\n",
      "           3       0.00      0.00      0.00       558\n",
      "           4       0.00      0.00      0.00       559\n",
      "           5       0.37      1.00      0.54      2843\n",
      "           6       0.00      0.00      0.00       534\n",
      "           7       0.00      0.00      0.00      1653\n",
      "           8       1.00      1.00      1.00      1005\n",
      "\n",
      "    accuracy                           0.61     12376\n",
      "   macro avg       0.37      0.44      0.39     12376\n",
      "weighted avg       0.46      0.61      0.50     12376\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "abc = AdaBoostClassifier(n_estimators=50,\n",
    "                         learning_rate=1)\n",
    "# Training\n",
    "model = abc.fit(X_train, y_train)\n",
    "abc_predictions = model.predict(X_test)\n",
    "print(classification_report(y_test , abc_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "95667512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60.681965093729794"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, abc_predictions)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d3e661",
   "metadata": {},
   "source": [
    "## Comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "17702118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = {'KNN': knn_predictions, 'Logistic Regression': lor_predictions, 'Linear Regression': lr_predictions, 'Decsion Tree':dt_predictions, 'Random forest':rf_predictions,'Neural network':mlp_predictions,'Naive Bayes':nb_predictions,'Adaboost':abc_predictions}\n",
    "d = pd.DataFrame(df)\n",
    "corr = d.corr()\n",
    "sns.heatmap(corr, xticklabels=corr.columns, yticklabels=corr.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdfe7c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
